20191226：
	jsub:
		-参考具体的刻度 作为案例
		-做报告的方法
		-面向未来
		
		calibration for a concrete example.
		-/junofs/users/wxfang/JUNO/jobs/make_batch.py
		-/junofs/users/wxfang/JUNO/jobs/setDEto1/job_0.sh

        m_z = m_r*math.cos(j*math.pi/180)
        m_x = m_r*math.sin(j*math.pi/180)*math.cos(i*math.pi/180)                          
        m_y = m_r*math.sin(j*math.pi/180)*math.sin(i*math.pi/180)     		
		
		
20191224:
	jsub:
		-new pword for yangyf@IHEPKRBS:	yyf,1992
		-juno package:

			-to run a specific package, the .so file of the compiled package should lie in $LD_LIBRARY_PATH 
			
			-how to work in juno?
				-source env:
					/cvmfs/juno.ihep.ac.cn/sl6_amd64_gcc494/Pre-Release/J19v1r0-Pre3/setup.sh
				-for compilation, one needs work area:
					
				-for simple run, just use runtime env without workarea.
20191223:
	jsub:
		-dataset:
			/cvmfs/dcomputing.ihep.ac.cn/frontend/gangadist/1.2.5/install/5.6.2/python/GangaBoss/Lib/Dataset
		-learn from gangaboss:
			-how did it get boss env for remote wn?
				/cvmfs/dcomputing.ihep.ac.cn/frontend/gangadist/scripts/libcurl.patch
			-
			
			
20191222:
	Luminosity memo:
		-回答张景芝老师问题
			

20191218:
	JSUB:
		github
			-connect my computer/ssh with github.
			-updated the repo.
		
		rename things:
			-navigator should be renamed to driver		
			-app extension should be renamed to interface
			-content dir should be renamed to 
			-repo dir should be renamed to
			-work dir should be renamed to 

20191217:
	JSUB:
		-JUNO's action script:
			https://juno.ihep.ac.cn/mediawiki/index.php/Offline_Software#Getting_Started
			/afs/ihep.ac.cn/soft/juno/JUNO-ALL-SLC6/Pre-Release/J19v1r0-Pre3/offline/Validation/JunoTest/production		
		
			-need juno env on remote:

				/cvmfs/juno.ihep.ac.cn/sl6_amd64_gcc494/Pre-Release/J19v1r0-Pre3		?
			-go over it offline.
				
		
20191212：
	JSUB:
		-need to add functionality graph.
		-need to modify jsub_workflow graph.
			-user-oriented version
			-rename extensions	
				-changes in code.
		-need to implement jsub functionalities:
			-jsub show		-done
			-jsub query		
			-jsub getoutput

20191211:
	dirac computing model:
		Antunes-Nobrega, R., et al.: (LHCb) LHCb TDR
		Computing Technical Design Report. Tech. Rep.
		LHCb CERN-LHCC-2005-019 (2005)
	JSUB:
		-jsub create
			-all_files_in_folder should take path relative to job definition file?	
				-hard to implement; 
				-just to take it as tolerable behavior for now?
				-translate to abspath in app?
			

20191210:
	JSUB:
		-jsub register
			use dm.putAndRegister() instead of dm.registerFile()
				-otherwise file would not exist in SE.	(file exists in SE would be accessible from /cefs/user/y/yyang/)
				
			-can successfully upload, but the file can't be downloaded.
			
			 Failed to put file to Storage Element. cepc-user-y-yyang.lfns: BOSS CVMFS not found ( 70 : Failed to copy file cepc-user-y-yyang.lfns to destination url srm://storm.ihep.ac.cn:8444/srm/managerv2?SFN=/cepc/user/y/yyang/x.txt: [70] [gfalt_copy_file][perform_copy][srm_plugin_filecopy][srm_resolve_turls][srm_resolve_put_turl] DESTINATION OVERWRITE [srm_plugin_prepare_dest_put][srm_plugin_delete_existing_copy][gfal_srm_unlinkG][gfal_srm_report_error] srm-ifce err: Communication error on send, err: [SE][srmRm][] httpg://storm.ihep.ac.cn:8444/srm/managerv2: CGSI-gSOAP running on lxslc614.ihep.ac.cn reports Error reading token data header: Connection closed
				-error caused by pressure test?
		
		-succeeded in making the "run_general_script" test case working.

20191209:
	CEPC meeting:
		-data object的关联
		-GearDET
		-3 collections: MC particles; digitized hits; (link)
		
	JSUB:
		-no responce when trying to dirac-dms-get-file.
			-pressure test?
		-jsub register:
			lfn: must start with /cepc/user/{user-first-char}/{user-name}/				lfn=/cepc/user/y/yyang/ + path_to_upload
			file to upload: must be in /cefs
			
			avoid too-many-level problem: (16 / in path)
		

20191208:
	JSUB:
		[2019-12-08 14:00:12 UTC][JSUB|DEBUG]:  - Standard error:Traceback (most recent call last):  File "/mnt/data/scratch/lcg/pilcepc30/42971677/CREAM782938190/DIRAC_ConZyYpilot/Linux_x86_64_glibc-2.12/bin/gfal-copy", line 8, in <module>    from gfal2_util.shell import Gfal2ShellImportError: No module named gfal2_util.shell

		-the problem is that there is no dirac environment on remote, so can't run gfal command.
		
		-jsub register can now take a folder as parameter.
		
		/junofs/users/yangyf/jsub/examples/test_juno/input_files
		/cvmfs/dcomputing.ihep.ac.cn/dirac/IHEPDIRAC/v0r1/DIRAC/DataManagementSystem/scripts/dirac-dms-user-lfns.py
		/cvmfs/dcomputing.ihep.ac.cn/dirac/IHEPDIRAC/v0r1/DIRAC/Interfaces/scripts/dirac-dms-get-file.py
		/cvmfs/dcomputing.ihep.ac.cn/dirac/IHEPDIRAC/v0r1/DIRAC/DataManagementSystem/scripts/dirac-dms-add-file.py
		
		/cepc/user/y/yyang/junofs/users/yangyf/jsub/examples/test_juno/input_files/2.txt
			-no accessible replicas found
			
			BOSS CVMFS not found ( 70 : GError('srm-ifce err: Communication error on send, err: [SE][Mkdir][] httpg://storm.ihep.ac.cn:8444/srm/managerv2: CGSI-gSOAP running on lxslc603.ihep.ac.cn reports Error reading token data header: Connection closed\n', 70))

			
		
		
		LFN does not follow the DIRAC naming convention
		/vo/* or /sandbox/*

20191206:
	JSUB:
		

20191205：
	JSUB:
		learn from Belle 2:
			-Belle 2 Dirac frontend;
			-ILC Dirac;
		Report on JSUB:
			-how to introduce my work to others?
			-software structure;
			-details:
				-how to write task description file;
				-how to write jsubrc file.
				-how to interact with dirac?
			-how do users use it;
			
	
	Opticks: GPU optical simulation via Nvidia / a Mental model for efffective application of GPUs
		Simon Blyth
		JUNO
		geant 4: toolkit
			-using a tiny part of it 
		problem:
			huge CPU memory + time expense(99% CPU time, memory constraints)
				-any detector that use scintilattors may have the same problem
				-what takes time is not the physics, but the inquiry of the detector info.
			only interested in scintillation/ not cherenkov
			
		solving problem:
			-optical photon simulation ~=ray traced image rendering
				-rasterization/ray tracing
				-nvidia ray tracing GPU in 2018
			-opticks:
				-geant 4+ opticks hybrid workflow
				-translation of geometry
					-find repeated element (instancing technique)
					-approximate geometry/ analytic geometry;
					-random aligned bi-simulation:
						-same input to Opticks and Geant 4;
						-point by point aligned for both methods;
							-not clouded by statistics; efficient way to find problems
							-grazing incidence, edge skimmers; incidence at constituent solid boundaries (<0/05% dif)
							-display technique (select event through their history)
		performance:
			-GPU/CPU comparison; (num of core problem)
			-effective geometry/ full geometry;
			-nvidia claim: 10 giga rays/s
		
		lesson learned:
			-physics should enjoy the fruit of industry;
				-in geant 4 case: just put geometry to GPU, and can easily get 1000x performance.
				-games -> graphics revolution -> GPU -> cheap TFLOPs
				-internet scale big datasets -> ML revolutions
				-computer vision revolution for autonomous vehicles
			
	The general application of the techniques/tools from the practice above:
		-GPU mental model: context and constraints
			-amdahls law: how much of the speed up can be obtained with parallielization
				-removing bottlenecks one by one.
			-GPU graphical origins -> effective GPU computation (rasterization)
				GPU evolved to rasterize 3D graphics at 30/60 fps
				
				-cpu is latency-oriented; avoid latency with caching
				-gpu is throughput-oriented; hide latency with parallelism
				-totally different processor architecture( different shape of data/computation)
			-how to make effective use of GPUs?
				-abundant parallelism
				-simplicity(array) 0> big benefits: NumPy + CuPy;
					objected-oriented: mixing data/compute;
					array-oriented: separate data from compute;
				-parallel processing 0th step: re-shape data into "parallel" array form;
					photo(400m,4,4): first dimension shall be large;
				-using CUDA:
					thread hierarchy; memory hierarchy;
					CuPy: the simplest CUDA interface.
						numpy API accelorated with CUDA;
						production CuPy?
							-if integration (eg Geant 4, OpenGL): no 
							-control + performance
					C++ based interfaces:
						-Thrust
						-CUB
						-MGPU
					mature NVIDIA basis libraries
					RAPIDS
				
				NumPy;
					loading numpy array from C/C++ (github.com/simoncblyth/np)
					access/create array data anywhere.
			-when python not appropriate:
				try first CUDA thrust.
				
			
20191204:
	JSUB:
		dirac backend:
			-rename "dirac input" and "dirac output" to dirac_download and dirac_upload
			-dirac_download module:
				-use gfal-copy command to download file
				-input file specified by os.environ('JSUB_input_file')
				-put the input file to the ../ of the action folder.
				-use basename of input file.
				-further customization: dest_path, dest_basename
			
			-a command to register input files on dirac-file-catalog.
				-`jsub register file_list`.
				-run 'command/scripts/dirac-register.py
				-success (can be seen in dirac-dms-filecatalog-cli)
				-need to also put the files there. (with a switch)
				-to do: customize path of lfn.
	
		a general script module:
			-users shall define the files to output.
				

	网格组会：
		Biyujiang: 
			-Belle 2 站点设置
				-安装EOS
					-本地能工作吗？
					-grid 服务
				-grid ftp
					-server 和存储节点的结合
					
				-dcache: 文件传输命令
					-xrootd 3rd party copy
					
		jiangxiaowei:
			-网格与网格中间件的结合
		
		
					
					
20191202：
	JSUB:
		preparing for JUNO review:
			-UI
				-learn from: ILC dirac
				-
			-job handling:
				reschedule
			-data management
				-data transfer on grid.
			-experiment specific modules:
				-CEPC:
					-sim, rec
				-JUNO:
					-generic
				
				