20191127:

	JSUB JUNO:
		-JUNO workflow
			tut_detsim.py
			tut_det2calib.py
			tut_calib2rec.py

			
		-JSUB for users
			-analysis
				input: MC info, 
				output: 
				
				low priority?
				
				ROOT script. No sniper env needed.
				
				bookkeeping: rec data; not user data.
					-using data here.
					-api: 欧歌
				using file catalog.
					-connecting with bookkeeping
			-
			
20191126:
	Dirac data management:
		use gfal copy to put data into dir;
			which dir?
				../ of the action run dir.
				file name = basename of the input file.
			when running on dirac backend, the input/output in the mid-steps are changed to ../ dir.
			
			handling the input of gear_xml_file on dirac backend.
				-copy into input common dir; and use this replicate on dirac backend.
			
		show/reschedule backend job id:
			need to save backend job id: 
				modify repo exts
		
		to do:
			deal with multiple submit:
				update task id;
					done
			define task status.
				
	
		example LFN: /cepc/lustre-ro/cefs/data/FullSim/CEPC240/CEPC_v4/higgs/E240.Pnnh_X.e0.p0.whizard195
		successful with dirac-dms-lfn-metadata
		failed with dirac-dms-catalog-metadata:
			No such file or directory
				(is this permission error?)
				
		
		
	JSUB:
		-need to prepare for JUNO review: 2020, January 11th.
		-to do: read codes of dsub.
			/cepc/lustre-ro/cefs/data/DstData/qqh/qqh/E250-CDR_ws.Pqqh.eU.pU.03611.slcio
			
		-how to deal with output dir when on dirac?
			sim output dir:
				local: workflow['cepc_sim']['actvar']['output_dir']
				dirac: workflow['dirac_output']['actvar']['sim_output_dir']
			rec output dir:
				local: workflow['cepc_rec']['actvar']['output_dir']
				dirac: workflow['dirac_output']['actvar']['rec_output_dir']	

		-provide a DIRAC-like API
			(like ILCDIRAC)
	
		-job show/reschedule
	
20191125:
	JSUB:
		-use environ variables instead of command line arguments for dirac_get_file.
			done
			dirac-dms-filecatalog-cli
				-can't get basic commands working.
		-permission denied:
			找颜田创立目录
			
		-to do: deal with dirac_add_file:
			how to deal with input/output files?
				output dir (for sim, rec)
				output file name.
				permission
	

	Software group meeting for next CEPC Collaboration meeting:

		-zoujh: 数据模型的关联
			-tool for cheating-level analysis
			-LCIO-> PLCIO；没法等待官方版本
			-模拟时一一映射
			
		-tracking:
		
		-EMC:
			-digitalization example working?
			-use overlapping?
			-transporting
			
		-ACTS
			张晋
		
		-Fast tracking
			-TPC: 有偏、精度差（silicon的1/10)
		
		-Pandora
			PFA(Arbor)
			
		-distributed computing:
			-data management
			-JSUB 
			-Rucio
		
		-flavor tagging
			
		
	要延续之前别人提到的关键的地方
	要让别人看到我们在工作。
		-sense of progression.
		
	
	
20191120:
	CHEP:
		wlcg-hsf: joined together
		-quicker analyses: abundant resources, analysis model(less data; interactive ana)
		-new authentication (token based)
			no need to apply for certs;
			

	jsub:
		FC:/cepc/lustre-ro/cefs/data/stdhep/CEPC240

20191119:
	jsub:
		-understand JSUB-dirac:
			jobs were submitted with a command.
			how to get job id of submitted job?
				the output of subprocess is returned as json, and interpreted by dirac/backend/__init__.py
				is returned in the result of submit in operation/backend_manager
				
				-where to put this result so that it can be used by the retrieval?
			
			dirac-wms-job-status <jobID>
			dirac-wms-job-get-output <jobID>
			
		-how to debug a job in dirac?
			elicit output?
				print to ../../../../jsub.out in workflow steps.

		-cepc-dirac:
			need to return job-id. and be used for show.
			Thread "cepc_sim" exception (OSError): [Errno 13] Permission denied
		
		
		-cepc app:
			use dirac_output_dir instead of output_dir?

20191118：
CEPC Software Meeting
	Status of CEPC computing
		zhang xiaomei
		computing model:	
			IHEP as central site;
				Event Generation, MC production, analyses
				hold central storage/database for all experiment data/ detector geometry
			remote sites: 
				MC production including Mokka simu + Marlin recon
			data flow:
				IHEP-> Sites: stdhep files
				sites -> IHEP: 

	Rucio: Scientific Data Management
		https://rucio.cern.ch/	
		https://rucio.readthedocs.io  
		https://github.com/rucio
	
		a data management service:
			seamless integration of storage and network
			data stored in files, can contain any potential payload
			facilities can be distributed at multiple locations belonging to different admin domains
			designed with extensive operational experience
		functionalities:
			file and dataset catalog
			transfer between facilities including disk, tapes, clouds, HPCs
			web-UI, CLI and API to discover/download/upload/transfer/annnotate data.
		
			data carousel
				tight integration of workflow and dataflow, for more efficient use of high-latency storage (i.e., tape)
			rucio concepts:
				declarative data management:
					express what you want, not how you want it.
					replication rules.
						dynamic
				Rucio Storage Elements(RSEs)
					no software needed,
					collect all necessary metadata: protocols, hostname, ports, prefixes, paths, implementations.
				Metadata:
					file internal metadata/ fixed physics/ internal metadata for organization of data, generic metadata
			architecture:
			operations model:
				minimize human intervention
				

	CMS Software Stacks:
		Tommaso Boccali
			Computing at LHC: size, status, tasks
				LHC: in shutdown after 2015-2018 run, currently 5% of the luminosity
				typical experiments needs @ 2018: evens to offline ~GB/s (tier0), events to GRID (some GB/s), 500 users per week submitting analyses
				data management: thousands of daily decisions taken by a policy driven system.
			The software stacks: components, tools
				sim
				rec
				ana
			The main SW components
				-core code
				-data management, workload management
				-main external tools.
					from running on a single node to the grid:
						-distribute data efficiently: O(5000) datasets appearing per week.
						-distribute software.
						-distribute calibrations.
				
				algorithms(tracking, clustering, vertexing, ...)
					must live in a scalable environment with stable APIs, sandboxing for multi threading, offloading etc
				needs from a framework:
					-multi threading infrastructure
						-memory under control, in case of large payloads
						-grants/ access to special machines for targeted production
					-heterogeneous computing:
						GPU/FPGA
						if GPU is found, run with GPU; otherwise with C.
					-
				
				
20191117:
	jsub:
		error when no input assigned.
			

	jsub-dirac:
		-minimal_dirac task:
			-work/job missing.
			-job successfully run though.
		-sim_dirac task:
			-error when creating task: files to register must be under /cefs
			-use a new stdhep filelist, with files in /cefs/		
				successfully created the task; list of files to register is right
			-can't submit the task:
				FileNotFoundError: [Errno 2] No such file or directory: '/junofs/users/yangyf/jsub-dirac/jsub_dirac/action/dirac_input/run'
					-fixed. 
						error cause: param.yml in action extension not rightfully parsed.
			-make the task work as intended:
				-dirac_get_file.py should use the input files.
					-how does python files use input parameters?
						
				-how to set the output 
					can get jobvar in python script with sys.argv
					can get actvar in python script with os.environ.get(key,default_value)
				-work with py instead of sh.
					-#!/usr/bin/env python


20191115:
	learn python:
		__file__, __cwd__, os.path.dirname(__file__), os.path.realpath(__file__)

	jsub-dirac:
		-zhaoxh already updated jsub-dirac, need to test
			-missing launcher param main_pack_file
				-didn't load launcher from jsub-dirac pack.
					-dealt with after modifying .jsubrc
			-cepc-dirac:
				-need to register data in cepc_app:
					check if backend['name']='dirac'
						register data:
					
				-need to download/upload data in action.
					-modified jsub_cepc app
					-added jsub_dirac actions: dirac_input, dirac_output
				

20191114:
	coding jsub-dirac extension:
		param={'work_dir': '~/jsub/work'}
		launcher_param={'executable': 'launcher.sh'}


20191113:
	coding jsub dirac: 
		-try to source dirac, and run jsub:
			(venv python 3.7)
			-pip not working after source dirac:
				-venv not in $PATH
			-create and submit a task with local backend (after source dirac env):
				success in create/submit
			-create and submit a task with dirac backend:
				error: handled by python 3.7
				
			(venv with python 2.7)
			-create and submit a task with local backend (without source dirac env):
				success
			-create and submit a task with local backend (after source dirac env):
				Could not find platform independent libraries <prefix>
				Could not find platform dependent libraries <exec_prefix>
				Consider setting $PYTHONHOME to <prefix>[:<exec_prefix>]
				ImportError: No module named site
				
			-try to python -V:
				python: error while loading shared libraries: libpython2.7.so.1.0: cannot open shared object file: No such file or directory
				-it seems that the python 2.7.15 from /cvmfs/dcomputing.ihep.ac.cn is installed wrongly?
					-has to load module python2.7.15 and common1.0 again when reentering the env.
			
			where did the error occurred:
				-after modifying LD_EXTERNAL_LIB
					-can work around by changing the order of the original $LD_LIBRARY_PATH to the added content.
			
					-try to create a of dirac init script of my own.
						-doesn't solve the problem: DIRAC only works in its own python env, not in the one with jsub.
			
20191111:
	CEPC Meeting:
		-Fu chengdong: migration of tracking alg from Marlin to CEPCSW
		-Fangwx: GAN for simulation
		-lintao: detector simulation protocol

	jsub:
		-problem: jsub use the virtualenv, while dirac provide its own python.
			-not feasible to use jsub outside the virtualenv, 
			-not solvable by creating a python 2.7 virtualenv; failed
			-not possible to migrate dirac to python 3.
			-

20191110:
	test about zhangjz's question:
		-added normPH requirement in ics=14,15
	CEPC dirac:
		-certificate password: yyf1992
		
export DIRAC=/cvmfs/dcomputing.ihep.ac.cn/dirac/IHEPDIRAC/v0r1
source $DIRAC/bashrc
dirac-proxy-init -g cepc_user -v 96:00

PATH=/afs/ihep.ac.cn/users/y/yangyf/virtual_env/venv/bin:$PATH			#to solve the pip-jsub problem.


20191107:
	Draft about luminosity:
		-reply to zhangjz:
			45070	MDC+EMC CutReduce without normPH
			44800	MDC+EMC CutReduce
			32625496 total
			188442  MDC +EMC one low energy
			156843  E1>1.55, E2<1.50
				-compare with the result of (E1>1.55, E2<1.55*0.5)
			重交作业后得到E1>1.55,E2<0.775的事例数
		-reply to zhouxy:
			-polish english
				changes to make according to the link:
					https://hnbes3.ihep.ac.cn/HyperNews/get/paper340/10.html
			-改图：
				-直接修改img/draft180604/文件夹中的.C文件
					-can already generate png files from .C files.
					-finished the update.
			-target journal
			-改motivation
		-removed the red text hightlight for previous version.

20191104：
	CHEP relevant report about data access:
		https://indico.cern.ch/event/805983/contributions/3569724/attachments/1937437/3211168/FutureAnalysis-WLCGHSF2019-Adelaide-v2.0.pdf

20191101:
	coding cepc_rec extension:
		-succeessed in transporting and modifying reco.xml
			-how to deal with users' custom patterns in writing reco.xml?	(new lines/ no new lines in parameters)
			-how to deal with tree output files?
			-how to deal with GearXMLFile?
			-event max in rec.
			-intervals between steps in workflow
		-need to configure files for reco.xml
		
		-connecting sim+rec:

			[ ERROR "MyForwardTracking"] Collection FTDPixelTrackerHits is not available!
			[ ERROR "MyForwardTracking"] Collection FTDSpacePoints is not available!
			[ ERROR "MyTrackSubsetProcessor"] Collection ForwardTracks is not available!
			-bad slcio output from sim.
